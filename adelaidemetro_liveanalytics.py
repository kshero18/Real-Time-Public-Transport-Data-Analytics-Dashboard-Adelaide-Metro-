# -*- coding: utf-8 -*-
"""AdelaideMetro-LiveAnalytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K-hpm39p7qDn_hfAu0GuHyfcmoyRlzrA
"""

!pip install gtfs-realtime-bindings
!pip install gtfs-realtime-bindings pandas requests

import requests
from google.transit import gtfs_realtime_pb2

url = "https://gtfs.adelaidemetro.com.au/v1/realtime/trip_updates"

headers = {
    "User-Agent": "Python-DataClient/1.0 (mailto:ksheerajaksr@gmail.com)",
    "Accept": "application/x-google-protobuf"
}

resp = requests.get(url, headers=headers)
print("HTTP Status:", resp.status_code)

if resp.status_code == 200:
    feed = gtfs_realtime_pb2.FeedMessage()
    feed.ParseFromString(resp.content)
    print(f"Feed contains {len(feed.entity)} trip updates")

    # Example: print first few trips
    for entity in feed.entity[:5]:
        if entity.HasField("trip_update"):
            trip = entity.trip_update
            print("Trip:", trip.trip.trip_id, "| Route:", trip.trip.route_id)
else:
    print("Error:", resp.text)

import requests
import pandas as pd
from google.transit import gtfs_realtime_pb2

url = "https://gtfs.adelaidemetro.com.au/v1/realtime/trip_updates"
headers = {
    "User-Agent": "Python-DataClient/1.0 (mailto:ksheerajaksr@gmail.com)",
    "Accept": "application/x-google-protobuf"
}

resp = requests.get(url, headers=headers)
feed = gtfs_realtime_pb2.FeedMessage()
feed.ParseFromString(resp.content)

records = []
for entity in feed.entity:
    if entity.HasField("trip_update"):
        trip = entity.trip_update
        for stop_time in trip.stop_time_update:
            records.append({
                "trip_id": trip.trip.trip_id,
                "route_id": trip.trip.route_id,
                "stop_id": stop_time.stop_id,
                "arrival_delay": stop_time.arrival.delay if stop_time.HasField("arrival") else None,
                "departure_delay": stop_time.departure.delay if stop_time.HasField("departure") else None,
                "timestamp": trip.timestamp
            })

df = pd.DataFrame(records)
print(df.head())

# Save to CSV for Power BI
df.to_csv("adelaide_metro_trip_updates.csv", index=False)

!pip install flask

!pip install flask pyngrok gtfs-realtime-bindings requests

!ngrok config add-authtoken 34Y3K0u3fWnNpMu1DjSLtMOHKCB_6fBJ6qzJw3c7m9f96k8bW

from flask import Flask, jsonify
from pyngrok import ngrok
import threading, time, requests
from google.transit import gtfs_realtime_pb2

app = Flask(__name__)

# shared variable for the latest data
latest_data = []

def refresh_data(interval=60):
    """Fetch live Adelaide Metro data every <interval> seconds."""
    global latest_data
    while True:
        try:
            url = "https://gtfs.adelaidemetro.com.au/v1/realtime/trip_updates"
            headers = {
                "User-Agent": "Python-DataClient/1.0 (mailto:ksheerajaofficial@gmail.com)",
                "Accept": "application/x-google-protobuf"
            }
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                feed = gtfs_realtime_pb2.FeedMessage()
                feed.ParseFromString(resp.content)
                new_data = []
                for entity in feed.entity:
                    if entity.HasField("trip_update"):
                        trip = entity.trip_update
                        for stop_time in trip.stop_time_update:
                            new_data.append({
                                "trip_id": trip.trip.trip_id,
                                "route_id": trip.trip.route_id,
                                "stop_id": stop_time.stop_id,
                                "arrival_delay": stop_time.arrival.delay if stop_time.HasField("arrival") else None,
                                "departure_delay": stop_time.departure.delay if stop_time.HasField("departure") else None,
                                "timestamp": trip.timestamp
                            })
                latest_data = new_data
                print(f"[✓] Updated {len(new_data)} rows at {time.strftime('%H:%M:%S')}")
            else:
                print("HTTP error:", resp.status_code)
        except Exception as e:
            print("Refresh error:", e)
        time.sleep(interval)

@app.route("/data")
def get_data():
    """Return the latest in-memory dataset."""
    return jsonify(latest_data)

# create tunnel
public_url = ngrok.connect(addr="5000", proto="http")
print("Public URL:", public_url)

# start background refresher thread
threading.Thread(target=refresh_data, daemon=True).start()

# run Flask server
app.run(host="0.0.0.0", port=5000)

print(f"Rows loaded: {len(latest_data)}")

"""vehicle positions

"""

from flask import Flask, jsonify
from pyngrok import ngrok
import threading, time, requests
from google.transit import gtfs_realtime_pb2

app = Flask(__name__)

latest_data = []

def refresh_data(interval=60):
    """Fetch Adelaide Metro Trip + Vehicle data every <interval> seconds."""
    global latest_data
    while True:
        try:
            # Trip updates (delays, stops)
            trip_url = "https://gtfs.adelaidemetro.com.au/v1/realtime/trip_updates"
            vehicle_url = "https://gtfs.adelaidemetro.com.au/v1/realtime/vehicle_positions"
            headers = {
                "User-Agent": "Python-DataClient/1.0 (mailto:ksheerajaofficial@gmail.com)",
                "Accept": "application/x-google-protobuf"
            }

            trip_feed = gtfs_realtime_pb2.FeedMessage()
            trip_feed.ParseFromString(requests.get(trip_url, headers=headers).content)

            vehicle_feed = gtfs_realtime_pb2.FeedMessage()
            vehicle_feed.ParseFromString(requests.get(vehicle_url, headers=headers).content)

            # Convert vehicle data to lookup table by trip_id
            vehicle_lookup = {}
            for entity in vehicle_feed.entity:
                if entity.HasField("vehicle"):
                    v = entity.vehicle
                    vehicle_lookup[v.trip.trip_id] = {
                        "latitude": getattr(v.position, "latitude", None),
                        "longitude": getattr(v.position, "longitude", None),
                        "speed": getattr(v.position, "speed", None)
                    }

            new_data = []
            for entity in trip_feed.entity:
                if entity.HasField("trip_update"):
                    trip = entity.trip_update
                    vinfo = vehicle_lookup.get(trip.trip.trip_id, {})
                    for stop_time in trip.stop_time_update:
                        new_data.append({
                            "trip_id": trip.trip.trip_id,
                            "route_id": trip.trip.route_id,
                            "stop_id": stop_time.stop_id,
                            "arrival_delay": stop_time.arrival.delay if stop_time.HasField("arrival") else None,
                            "departure_delay": stop_time.departure.delay if stop_time.HasField("departure") else None,
                            "latitude": vinfo.get("latitude"),
                            "longitude": vinfo.get("longitude"),
                            "speed": vinfo.get("speed"),
                            "timestamp": trip.timestamp
                        })

            latest_data = new_data
            print(f"[✓] Updated {len(new_data)} records at {time.strftime('%H:%M:%S')}")
        except Exception as e:
            print("Refresh error:", e)
        time.sleep(interval)

@app.route("/data")
def get_data():
    return jsonify(latest_data)

public_url = ngrok.connect(addr="5000", proto="http")
print("Public URL:", public_url)

threading.Thread(target=refresh_data, daemon=True).start()
app.run(host="0.0.0.0", port=5000)